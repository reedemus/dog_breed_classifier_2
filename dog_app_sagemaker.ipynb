{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkRhjEX2a0uK"
   },
   "source": [
    "# Train and Deploy Custom Model in AWS\n",
    "\n",
    "## Project: Train, Evaluate and Deploy Dog Identification App in SageMaker\n",
    "---\n",
    "### Why We're Here \n",
    "In this notebook, we will train and deploy a **custom model** in SageMaker. Specifically, the pretrained PyTorch model from  [Dog Breed Classifier](https://github.com/reedemus/dog_breed_classifier) project will be used as an example for this exercise. \n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps. Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 1](#step1): Upload the dataset into an S3 bucket\n",
    "* [Step 2](#step2): Create the custom model\n",
    "* [Step 3](#step3): Completing a training script\n",
    "* [Step 4](#step4): Training and deploying the custom model\n",
    "* [Step 5](#step5): Evaluating the performance\n",
    "---\n",
    "<a id='step1'></a>\n",
    "## Step 1: Upload the dataset to S3\n",
    "\n",
    "We will import the AWS SageMaker libraries and define helper functions for handling the dataset. We will download the dog dataset from [this URL](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip) and extract it before uploading them into the bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZjdgyqLa0uU"
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import requests\n",
    "import boto3\n",
    "import sagemaker\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `downloadFile` and `extractFile` helper functions to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(file_url, file_name, dir=None, chunk_size=1024):\n",
    "    '''\n",
    "    Helper function to download file to specified directory\n",
    "\n",
    "    :param file_url: file download URL\n",
    "    :param file_name: file name to be saved.\n",
    "    :param dir: path where file is saved other than current directory (Default = current working directory)\n",
    "    :param chunk_size: size of file chunk to download (Default = 1024 bytes)\n",
    "    :returns: None\n",
    "    '''\n",
    "    saved_file_path = file_name\n",
    "    if dir != None and not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        saved_file_path = os.path.join(dir, file_name)\n",
    "\n",
    "    r = requests.get(file_url, stream=True)\n",
    "    total_size_in_bytes = len(r.content)\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True, desc=file_name)\n",
    "    \n",
    "    with open(saved_file_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size):\n",
    "            progress_bar.update(len(chunk))\n",
    "            # writing one chunk at a time to file\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    progress_bar.close()\n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "       print(\"ERROR, something went wrong\")\n",
    "       return\n",
    "\n",
    "def extractFile(file_name):\n",
    "    '''\n",
    "    Extracts compressed file in zip format into current directory\n",
    "    \n",
    "    :param file_name: file name\n",
    "    :returns: None\n",
    "    '''\n",
    "    # create a zipfile object and extract it to current directory\n",
    "    print(\"Extracting file...\")\n",
    "    with ZipFile(file_name, 'r') as z:\n",
    "        z.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downlaod the dataset into current directory. The default folder after extraction is `dogImages/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_l78X2Ma0uX"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "dog_url = 'https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip'\n",
    "\n",
    "downloadFile(dog_url, 'dogImages.zip')\n",
    "extractFile('dogImages.zip')\n",
    "\n",
    "# load filenames for human and dog images\n",
    "dog_files = np.array(glob(\"dogImages/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "- The S3 bucket and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the `sagemaker.get_execution_role()` with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Name of the dataset directory\n",
    "data_dir = 'dogImages'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'dog-breed-classifier'\n",
    "\n",
    "# upload all data to S3\n",
    "input_dataset = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test cell\n",
    "Test that our data has been successfully uploaded. The cell below prints out the items in the S3 bucket and will throw an error if it is empty. We should see the contents of ```data_dir``` and perhaps some checkpoints. If there are any other files listed, then we may have some old model files that can be deleted via the S3 console (though, additional files shouldn't affect the performance of model developed in this notebook).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CewCMDgDa0uY"
   },
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Create the custom model\n",
    "Create a CNN model to classify dog breed using transfer learning. The model is defined in `model.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwkiR2Tra0uY"
   },
   "outputs": [],
   "source": [
    "# Print the implementation using a Python syntax highlighter package\n",
    "!pygmentize model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Create the training script\n",
    "Once the model is developed, we implement the training script ```train.py```. The script does the following steps:\n",
    "\n",
    "1. Loads training data from a specified directory\n",
    "2. Parses any training & model hyperparameters (ex. nodes in a neural network, training epochs, etc.)\n",
    "3. Instantiates a model of your design, with any specified hyperparams\n",
    "4. Trains that model\n",
    "5. Finally, saves the model so that it can be hosted/deployed later\n",
    "\n",
    "From the code below, notice a few things:\n",
    "\n",
    "- Model loading (`model_fn`) and saving code\n",
    "- Getting SageMaker's default hyperparameters\n",
    "- Loading the training data\n",
    "\n",
    "If you'd like to read more about model saving with __[torch.save](https://pytorch.org/tutorials/beginner/saving_loading_models.html)__, click on the provided links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the implementation using a Python syntax highlighter package\n",
    "!pygmentize train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM8EPd9Ja0uk"
   },
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Create an Estimator\n",
    "When a custom model is constructed in SageMaker, an entry point must be specified. This is the Python file which will be executed when the model is trained; the `train.py` function you specified above. To run a custom training script in SageMaker, construct an estimator, and fill in the appropriate constructor arguments:\n",
    "\n",
    "- *entry_point*: The path to the Python script SageMaker runs for training and prediction.\n",
    "- *source_dir*: The path to the training script directory source_sklearn OR source_pytorch.\n",
    "- *role*: Role ARN, which was specified, above.\n",
    "- *train_instance_count*: The number of training instances (should be left at 1).\n",
    "- *train_instance_type*: The type of SageMaker instance for training. \n",
    "- *sagemaker_session*: The session used to train on Sagemaker.\n",
    "- *hyperparameters (optional)*: A dictionary { 'name':value, .. } passed to the train function as hyperparameters.\n",
    ">Note: For a PyTorch model, there is another optional argument *framework_version*, which you can set to the latest version of PyTorch.\n",
    "\n",
    "### Define the estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "rlTMZcywa0uo",
    "outputId": "3d8137ea-2f9c-4765-d179-53f06790874f"
   },
   "outputs": [],
   "source": [
    "# Define a PyTorch estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "# prefix is specified above\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate  the estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='code', # train.py at code directory\n",
    "                    role=role,\n",
    "                    py_version='py3',\n",
    "                    framework_version='1.10.0', # PyTorch version\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    hyperparameters={\n",
    "                        'epochs': 50,\n",
    "                        'batch-size': 64,\n",
    "                        'lr': 0.001\n",
    "                    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8_niqpia0up"
   },
   "source": [
    "### Train the estimator\n",
    "Train your estimator on the training data stored in S3. This should create a training job that you can monitor in your SageMaker console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsxfLM7Sa0ur"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({ 'train': input_dataset })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy the estimator\n",
    "\n",
    "After training, deploy your model to create a predictor. If you're using a PyTorch model, you'll need to create a trained PyTorchModel that accepts the trained <model>.model_data as an input parameter and points to the provided source_pytorch/predict.py file as an entry point.\n",
    "\n",
    "To deploy a trained model, you'll use `model.deploy`, which takes in two arguments:\n",
    "\n",
    "- initial_instance_count: The number of deployed instances (1).\n",
    "- instance_type: The type of SageMaker instance for deployment.\n",
    ">Note: If you run into an instance error, it may be because you chose the wrong training or deployment instance_type. It may help to refer to your previous exercise code to see which types of instances we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXSHZ-BSa0ur"
   },
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images.  Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ogXwn4Sa0us"
   },
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnterA7pa0ut"
   },
   "outputs": [],
   "source": [
    "# call test function    \n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCHq767-a0ut"
   },
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dogImages/train`, `dogImages/valid`, and `dogImages/test`, respectively). \n",
    "\n",
    "If you like, **you are welcome to use the same data loaders from the previous step**, when you created a CNN from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzYPwxCSa0ut"
   },
   "source": [
    ">__Note:__ Previous loaders cannot be re-used because the input image was resized to **256 x 256**, but models trained on ImageNet are **224 x 224**. So we have to start over writing a new loader, *loaders_transfer*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KNAm254a0uu"
   },
   "outputs": [],
   "source": [
    "## TODO: Specify data loaders\n",
    "# Note: pretrained models from ImageNet requires input images to be shape (3 x h x w) with h,w >= 224 and \n",
    "#       normalized to mean,std dev as per ImageNet (mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225])\n",
    "#\n",
    "# Reference: https://pytorch.org/vision/stable/models.html\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "root_dir = 'dogImages/'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "valid_dir = os.path.join(root_dir, 'valid')\n",
    "test_dir = os.path.join(root_dir, 'test')\n",
    "# ResNet input image size\n",
    "IMG_SIZE = 224\n",
    "# mean and std deviation of models trained on Imagenet dataset\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std_dev = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Data augmentation to create a variety of test images so the model learn to generalize better.\n",
    "# Output is a tensor.\n",
    "preprocess_train = transforms.Compose([\n",
    "                                    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "                                    transforms.RandomRotation(20),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize( mean, std_dev)\n",
    "                                    ])\n",
    "\n",
    "# Data augmentation is not performed on validation and test datasets because the goal is not to create more data,\n",
    "# but to resize and crop the images to the same size as the input image.\n",
    "# Output is a tensor.\n",
    "preprocess_valid_test = transforms.Compose([\n",
    "                                    transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(IMG_SIZE),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize( mean, std_dev)\n",
    "                                    ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=preprocess_train)\n",
    "valid_dataset = datasets.ImageFolder(valid_dir, transform=preprocess_valid_test)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=preprocess_valid_test)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "loaders_transfer = { 'train':train_loader, 'valid':valid_loader, 'test':test_loader }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hVlRBBya0uu"
   },
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Use transfer learning to create a CNN to classify dog breed.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6BxMI9Xa0uv",
    "outputId": "1e9354db-af3a-43cf-a9b7-3cdf3e106e0d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Using feature extraction approach\n",
    "# =================================\n",
    "# Freeze the weights for all of the network except the final fully connected(FC) layer.\n",
    "# This last FC layer is replaced with a new one with random weights and only this layer is trained.\n",
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#initialize-and-reshape-the-networks\n",
    "\n",
    "# ResNet 152-layer model\n",
    "model_transfer = models.resnet152(pretrained=True)\n",
    "\n",
    "# Freeze the pre-trained weights,biases of all layers at first so it doesn't get updated during re-training\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Get the number of input features in the last FC layer\n",
    "# Reinitialize output features to number of dog breed classes\n",
    "input_features = model_transfer.fc.in_features\n",
    "DOG_BREEDS_NUM = 133\n",
    "model_transfer.fc = nn.Linear(input_features, DOG_BREEDS_NUM)\n",
    "\n",
    "print(\"ResNet-152 last fc layer:\", models.resnet152().fc)\n",
    "print(\"Our fc layer:\", model_transfer.fc)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B3d8dNua0uw"
   },
   "source": [
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U5Al6zea0ux"
   },
   "source": [
    "__Answer:__\n",
    "From [PyTorch website](https://pytorch.org/vision/stable/models.html), ResNet152 has the lowest Top-1 and Top-5 errors among all the ResNet architectures. Also, the model has very good accuracy with a deep 152 hidden layers. Since it is pre-trained on ImageNet, which contains dog breed classes, the model is a pretty good candidate for our use case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAZItnAca0ux"
   },
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hIyw93ma0uy"
   },
   "outputs": [],
   "source": [
    "# use same as before\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.Adam( model_transfer.parameters(), lr=0.001 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ9lRNKBa0uy"
   },
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZxbRqLLa0uz"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "n_epochs = 40\n",
    "model_transfer = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
    "\n",
    "# save model to Google Drive\n",
    "if isColabRunning:\n",
    "    saveToDrive('model_transfer.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xl2BY5FQa0uz"
   },
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKJp4enYa0uz"
   },
   "outputs": [],
   "source": [
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3jEkAVPa0uz"
   },
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhKeC8PUa0u1"
   },
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "  \n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in loaders_transfer['train'].dataset.classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    image = Image.open(img_path).convert(mode='RGB')\n",
    "    IMAGE_SIZE = 224\n",
    "    # preprocess the image using transform\n",
    "    prediction_transform = transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(IMAGE_SIZE),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225] )\n",
    "                                        ])\n",
    "    image_tensor = prediction_transform(image).unsqueeze(0)\n",
    "    # move to GPU\n",
    "    if use_cuda:\n",
    "        image_tensor = image_tensor.cuda()\n",
    "    \n",
    "    # set to evaluation mode for inferencing\n",
    "    model_transfer.eval()\n",
    "    idx = torch.argmax(model_transfer(image_tensor))\n",
    "    return class_names[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoCv2xYSa0u2"
   },
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `dog_detector` functions developed above.  You are __required__ to use your CNN from Step 4 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/sample_human_output.png?raw=1)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "353cW-uHa0u2"
   },
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "def run_app(img_path):\n",
    "    '''handle cases for a human face, dog, and neither'''\n",
    "    # open image\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # predict its breed\n",
    "    breed = predict_breed_transfer(img_path)\n",
    "    \n",
    "    if face_detector(img_path) == True:\n",
    "        className = predict_breed_transfer(img_path)\n",
    "        msg = \"You are not a dog...but sure looks like a \" + str(className)\n",
    "    elif dog_detector(img_path) == True:\n",
    "        className = predict_breed_transfer(img_path)\n",
    "        msg = \"I'm guessing your dog is a \" + str(className) + \"!\"\n",
    "    else:\n",
    "        msg = \"Not a dog or human...what are you?\"\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(msg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86J01l-Ma0u3"
   },
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that _you_ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m-f3vJPa0u3"
   },
   "source": [
    "__Answer:__ (Three possible points for improvement)\n",
    "<br> Yes, the outputs are more accurate than the model output from the CNN designed from scratch.\n",
    "However, the model is unable to classify the last dog image which contains a yellow ball. Some improvements that can be tried are:\n",
    "1. Add more variety of images to the dog train dataset, which includes a dog with a ball.\n",
    "> a quick glance on the train dataset shows there is no dog images with a ball.\n",
    "2. Increase the training sample size for this dog breed class by finding more photos.\n",
    "3. Resize and crop the test image before feeding into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ3J-u8na0u4"
   },
   "outputs": [],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed.\n",
    "\n",
    "## suggested code, below\n",
    "for file in np.hstack((human_files[:3], dog_files[:3])):\n",
    "    run_app(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "dog_app.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
