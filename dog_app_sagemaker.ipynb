{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zkRhjEX2a0uK"
   },
   "source": [
    "# Train and Deploy Custom Model in AWS\n",
    "\n",
    "## Project: Train, Evaluate and Deploy Dog Identification App in SageMaker\n",
    "---\n",
    "### Why We're Here \n",
    "In this notebook, we will train and deploy a **custom model** in SageMaker. Specifically, the pretrained PyTorch model from  [Dog Breed Classifier](https://github.com/reedemus/dog_breed_classifier) project will be used as an example for this exercise. \n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps. Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Upload the dataset into an S3 bucket\n",
    "* [Step 1](#step1): Create the custom model\n",
    "* [Step 2](#step2): Completing a training script\n",
    "* [Step 3](#step3): Training and deploying the custom model\n",
    "* [Step 4](#step4): Evaluating the performance\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Upload the dataset to S3\n",
    "\n",
    "We will import the AWS SageMaker libraries and define helper functions for handling the dataset. We will download the dog dataset from [this URL](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip) and extract it before uploading them into the bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xZjdgyqLa0uU"
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import requests\n",
    "import boto3\n",
    "import sagemaker\n",
    "import zipFile as zf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define `downloadFile` and `extractFile` helper functions to download the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadFile(file_url, file_name, dir=None, chunk_size=1024):\n",
    "    '''\n",
    "    Helper function to download file to specified directory\n",
    "\n",
    "    :param file_url: file download URL\n",
    "    :param file_name: file name to be saved.\n",
    "    :param dir: path where file is saved other than current directory (Default = current working directory)\n",
    "    :param chunk_size: size of file chunk to download (Default = 1024 bytes)\n",
    "    :returns: None\n",
    "    '''\n",
    "    saved_file_path = file_name\n",
    "    if dir != None and not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "        saved_file_path = os.path.join(dir, file_name)\n",
    "\n",
    "    r = requests.get(file_url, stream=True)\n",
    "    total_size_in_bytes = len(r.content)\n",
    "    progress_bar = tqdm(total=total_size_in_bytes, unit='iB', unit_scale=True, desc=file_name)\n",
    "    \n",
    "    with open(saved_file_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size):\n",
    "            progress_bar.update(len(chunk))\n",
    "            # writing one chunk at a time to file\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    progress_bar.close()\n",
    "    if total_size_in_bytes != 0 and progress_bar.n != total_size_in_bytes:\n",
    "       print(\"ERROR, something went wrong\")\n",
    "       return\n",
    "\n",
    "def extractFile(file_name):\n",
    "    '''\n",
    "    Extracts compressed file in zip format into current directory\n",
    "    \n",
    "    :param file_name: file name\n",
    "    :returns: None\n",
    "    '''\n",
    "    # create a zipfile object and extract it to current directory\n",
    "    print(\"Extracting file...\")\n",
    "    with zf.ZipFile(file_name, 'r') as z:\n",
    "        z.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downlaod the dataset into current directory. The default folder after extraction is `dogImages/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_l78X2Ma0uX"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "dog_url = 'https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip'\n",
    "\n",
    "downloadFile(dog_url, 'dogImages.zip')\n",
    "extractFile('dogImages.zip')\n",
    "\n",
    "# load filenames for human and dog images\n",
    "dog_files = np.array(glob(\"dogImages/*/*/*\"))\n",
    "\n",
    "# print number of images in each dataset\n",
    "print('There are %d total dog images.' % len(dog_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a sagemaker session and a default S3 bucket. Then upload to bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# Name of the dataset directory\n",
    "data_dir = 'dogImages'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'dog images'\n",
    "\n",
    "# upload all data to S3\n",
    "dataset = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CewCMDgDa0uY"
   },
   "source": [
    "<a id='step1'></a>\n",
    "# Step 1: Create the custom model\n",
    "\n",
    "Create a CNN model to classify dog breed using transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwkiR2Tra0uY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Using feature extraction approach\n",
    "# =================================\n",
    "# Freeze the weights for all of the network except the final fully connected(FC) layer.\n",
    "# This last FC layer is replaced with a new one with random weights and only this layer is trained.\n",
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#initialize-and-reshape-the-networks\n",
    "\n",
    "# ResNet 152-layer model\n",
    "model_transfer = models.resnet152(pretrained=True)\n",
    "\n",
    "# Freeze the pre-trained weights,biases of all layers at first so it doesn't get updated during re-training\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Get the number of input features in the last FC layer\n",
    "# Reinitialize output features to number of dog breed classes\n",
    "input_features = model_transfer.fc.in_features\n",
    "DOG_BREEDS_NUM = 133\n",
    "model_transfer.fc = nn.Linear(input_features, DOG_BREEDS_NUM)\n",
    "\n",
    "print(\"ResNet-152 last fc layer:\", models.resnet152().fc)\n",
    "print(\"Our fc layer:\", model_transfer.fc)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AXqNaw6a0ue"
   },
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Detect Dogs\n",
    "\n",
    "In this section, we use a [pre-trained model](http://pytorch.org/docs/master/torchvision/models.html) to detect dogs in images.  \n",
    "\n",
    "### Obtain Pre-trained VGG-16 Model\n",
    "\n",
    "The code cell below downloads the VGG-16 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kM8EPd9Ja0uk"
   },
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, you will create a CNN that classifies dog breeds.  You must create your CNN _from scratch_ (so, you can't use transfer learning _yet_!), and you must attain a test accuracy of at least 10%.  In Step 4 of this notebook, you will have the opportunity to use transfer learning to create a CNN that attains greatly improved accuracy.\n",
    "\n",
    "We mention that the task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have trouble distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/Brittany_02625.jpg?raw=1\" width=\"100\"> | <img src=\"https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/Welsh_springer_spaniel_08203.jpg?raw=1\" width=\"200\">\n",
    "\n",
    "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
    "\n",
    "Curly-Coated Retriever | American Water Spaniel\n",
    "- | -\n",
    "<img src=\"https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/Curly-coated_retriever_03896.jpg?raw=1\" width=\"200\"> | <img src=\"https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/American_water_spaniel_00648.jpg?raw=1\" width=\"200\">\n",
    "\n",
    "\n",
    "Likewise, recall that labradors come in yellow, chocolate, and black.  Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
    "- | -\n",
    "<img src=\"https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/Labrador_retriever_06457.jpg?raw=1\" width=\"150\"> | <img src=\"https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/Labrador_retriever_06455.jpg?raw=1\" width=\"240\"> | <img src=\"https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/Labrador_retriever_06449.jpg?raw=1\" width=\"220\">\n",
    "\n",
    "We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.  \n",
    "\n",
    "Remember that the practice is far ahead of the theory in deep learning.  Experiment with many different architectures, and trust your intuition.  And, of course, have fun!\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dogImages/train`, `dogImages/valid`, and `dogImages/test`, respectively).  You may find [this documentation on custom datasets](http://pytorch.org/docs/stable/torchvision/datasets.html) to be a useful resource.  If you are interested in augmenting your training and/or validation data, check out the wide variety of [transforms](http://pytorch.org/docs/stable/torchvision/transforms.html?highlight=transform)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xr3Ozao_a0uk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "### TODO: Write data loaders for training, validation, and test sets\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "root_dir = 'dogImages/'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "valid_dir = os.path.join(root_dir, 'valid')\n",
    "test_dir = os.path.join(root_dir, 'test')\n",
    "IMG_SIZE = 256\n",
    "\n",
    "# Data augmentation to create a variety of test images so the model learn to generalize better.\n",
    "# Output is a tensor.\n",
    "preprocess_train = transforms.Compose([\n",
    "                                    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "                                    transforms.RandomRotation(20),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225] )\n",
    "                                        ])\n",
    "\n",
    "# Data augmentation is not performed on validation and test datasets because the goal is not to create more data,\n",
    "# but to resize and crop the images to the same size as the input image.\n",
    "# Output is a tensor.\n",
    "preprocess_valid_test = transforms.Compose([\n",
    "                                    transforms.Resize(384),\n",
    "                                    transforms.CenterCrop(IMG_SIZE),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                         std=[0.229, 0.224, 0.225] )\n",
    "                                        ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=preprocess_train)\n",
    "valid_dataset = datasets.ImageFolder(valid_dir, transform=preprocess_valid_test)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=preprocess_valid_test)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "loaders_scratch = { 'train':train_loader, 'valid':valid_loader, 'test':test_loader }\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ppxhKLVHa0ul"
   },
   "source": [
    "**Question 3:** Describe your chosen procedure for preprocessing the data. \n",
    "- How does your code resize the images (by cropping, stretching, etc)?  What size did you pick for the input tensor, and why?\n",
    "- Did you decide to augment the dataset?  If so, how (through translations, flips, rotations, etc)?  If not, why not?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0au1YMAMa0um"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "Using Pytorch transforms API, I resize the images to 256 x 256 resolution, which is a squarish format typically used in computer vision tasks. Also, this size uses less RAM for training as compared to 1024 x 1024 or higher.\n",
    "\n",
    "I decide to augment only the training dataset to create more variety of training images so the the model learns and generalizes better. This means the model can handle photos that are not shot perfectly in real life.\n",
    "\n",
    "However, the images in validation and test datasets are not augmented heavily(except resizing and cropping) as the objective is to have actual images for evaluation and not to artificially improve validation accuracy, which will lead to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRAEwLl0a0uo"
   },
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/stable/optim.html).  Save the chosen loss function as `criterion_scratch`, and the optimizer as `optimizer_scratch` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "rlTMZcywa0uo",
    "outputId": "3d8137ea-2f9c-4765-d179-53f06790874f"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "### TODO: select loss function\n",
    "criterion_scratch = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer_scratch = optim.Adam( model_scratch.parameters(), lr=0.001 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h8_niqpia0up"
   },
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_scratch.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ELyF41YGa0uq"
   },
   "outputs": [],
   "source": [
    "# the following import is required for training to be robust to truncated images\n",
    "import numpy as np\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            # zero the gradients accumulated from the previous backward propagation steps,\n",
    "            # make prediction, calculate the training loss, perform backpropagation, \n",
    "            # and finally update model weights and biases.\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion( output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # record the average training loss, using something like\n",
    "            # train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "            train_loss = train_loss + ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "        \n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        # switch model to evalution mode and disable gradient calculations to reduce memory usage\n",
    "        # and speed up computations since no backpropagation is needed in evaluation.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "                # move to GPU\n",
    "                if use_cuda:\n",
    "                    data, target = data.cuda(), target.cuda()\n",
    "\n",
    "                # get prediction from our model, calculate the validation loss\n",
    "                output = model(data)\n",
    "                loss = criterion( output, target)\n",
    "\n",
    "                ## update the average validation loss\n",
    "                valid_loss = valid_loss + ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "\n",
    "            # print training/validation statistics \n",
    "            print('Epoch {}: \\tTraining Loss: {:.3f} \\tValidation Loss: {:.3f}'.format(\n",
    "                epoch, train_loss, valid_loss))\n",
    "\n",
    "            ## TODO: save the model if validation loss has decreased\n",
    "            if valid_loss < valid_loss_min:\n",
    "                print('Saving Model...')\n",
    "                valid_loss_min = valid_loss\n",
    "                torch.save(model.state_dict(),save_path)\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsxfLM7Sa0ur"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "model_scratch = train(50, loaders_scratch, model_scratch, optimizer_scratch, \n",
    "                      criterion_scratch, use_cuda, 'model_scratch.pt')\n",
    "\n",
    "# save model to Google Drive\n",
    "if isColabRunning:\n",
    "    saveToDrive('model_scratch.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy\n",
    "model_scratch.load_state_dict(torch.load('model_scratch.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXSHZ-BSa0ur"
   },
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images.  Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ogXwn4Sa0us"
   },
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the loss\n",
    "        loss = criterion(output, target)\n",
    "        # update average test loss \n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnterA7pa0ut"
   },
   "outputs": [],
   "source": [
    "# call test function    \n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCHq767-a0ut"
   },
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "### (IMPLEMENTATION) Specify Data Loaders for the Dog Dataset\n",
    "\n",
    "Use the code cell below to write three separate [data loaders](http://pytorch.org/docs/master/data.html#torch.utils.data.DataLoader) for the training, validation, and test datasets of dog images (located at `dogImages/train`, `dogImages/valid`, and `dogImages/test`, respectively). \n",
    "\n",
    "If you like, **you are welcome to use the same data loaders from the previous step**, when you created a CNN from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZzYPwxCSa0ut"
   },
   "source": [
    ">__Note:__ Previous loaders cannot be re-used because the input image was resized to **256 x 256**, but models trained on ImageNet are **224 x 224**. So we have to start over writing a new loader, *loaders_transfer*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KNAm254a0uu"
   },
   "outputs": [],
   "source": [
    "## TODO: Specify data loaders\n",
    "# Note: pretrained models from ImageNet requires input images to be shape (3 x h x w) with h,w >= 224 and \n",
    "#       normalized to mean,std dev as per ImageNet (mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225])\n",
    "#\n",
    "# Reference: https://pytorch.org/vision/stable/models.html\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "## Specify appropriate transforms, and batch_sizes\n",
    "root_dir = 'dogImages/'\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "valid_dir = os.path.join(root_dir, 'valid')\n",
    "test_dir = os.path.join(root_dir, 'test')\n",
    "# ResNet input image size\n",
    "IMG_SIZE = 224\n",
    "# mean and std deviation of models trained on Imagenet dataset\n",
    "mean = [0.485, 0.456, 0.406]\n",
    "std_dev = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Data augmentation to create a variety of test images so the model learn to generalize better.\n",
    "# Output is a tensor.\n",
    "preprocess_train = transforms.Compose([\n",
    "                                    transforms.RandomResizedCrop(IMG_SIZE),\n",
    "                                    transforms.RandomRotation(20),\n",
    "                                    transforms.RandomHorizontalFlip(),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize( mean, std_dev)\n",
    "                                    ])\n",
    "\n",
    "# Data augmentation is not performed on validation and test datasets because the goal is not to create more data,\n",
    "# but to resize and crop the images to the same size as the input image.\n",
    "# Output is a tensor.\n",
    "preprocess_valid_test = transforms.Compose([\n",
    "                                    transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(IMG_SIZE),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize( mean, std_dev)\n",
    "                                    ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=preprocess_train)\n",
    "valid_dataset = datasets.ImageFolder(valid_dir, transform=preprocess_valid_test)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=preprocess_valid_test)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "loaders_transfer = { 'train':train_loader, 'valid':valid_loader, 'test':test_loader }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hVlRBBya0uu"
   },
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Use transfer learning to create a CNN to classify dog breed.  Use the code cell below, and save your initialized model as the variable `model_transfer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6BxMI9Xa0uv",
    "outputId": "1e9354db-af3a-43cf-a9b7-3cdf3e106e0d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Using feature extraction approach\n",
    "# =================================\n",
    "# Freeze the weights for all of the network except the final fully connected(FC) layer.\n",
    "# This last FC layer is replaced with a new one with random weights and only this layer is trained.\n",
    "# https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html#initialize-and-reshape-the-networks\n",
    "\n",
    "# ResNet 152-layer model\n",
    "model_transfer = models.resnet152(pretrained=True)\n",
    "\n",
    "# Freeze the pre-trained weights,biases of all layers at first so it doesn't get updated during re-training\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Get the number of input features in the last FC layer\n",
    "# Reinitialize output features to number of dog breed classes\n",
    "input_features = model_transfer.fc.in_features\n",
    "DOG_BREEDS_NUM = 133\n",
    "model_transfer.fc = nn.Linear(input_features, DOG_BREEDS_NUM)\n",
    "\n",
    "print(\"ResNet-152 last fc layer:\", models.resnet152().fc)\n",
    "print(\"Our fc layer:\", model_transfer.fc)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4B3d8dNua0uw"
   },
   "source": [
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U5Al6zea0ux"
   },
   "source": [
    "__Answer:__\n",
    "From [PyTorch website](https://pytorch.org/vision/stable/models.html), ResNet152 has the lowest Top-1 and Top-5 errors among all the ResNet architectures. Also, the model has very good accuracy with a deep 152 hidden layers. Since it is pre-trained on ImageNet, which contains dog breed classes, the model is a pretty good candidate for our use case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAZItnAca0ux"
   },
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/master/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/master/optim.html).  Save the chosen loss function as `criterion_transfer`, and the optimizer as `optimizer_transfer` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hIyw93ma0uy"
   },
   "outputs": [],
   "source": [
    "# use same as before\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion_transfer = nn.CrossEntropyLoss()\n",
    "optimizer_transfer = optim.Adam( model_transfer.parameters(), lr=0.001 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQ9lRNKBa0uy"
   },
   "source": [
    "### (IMPLEMENTATION) Train and Validate the Model\n",
    "\n",
    "Train and validate your model in the code cell below.  [Save the final model parameters](http://pytorch.org/docs/master/notes/serialization.html) at filepath `'model_transfer.pt'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ZxbRqLLa0uz"
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "n_epochs = 40\n",
    "model_transfer = train(n_epochs, loaders_transfer, model_transfer, optimizer_transfer, criterion_transfer, use_cuda, 'model_transfer.pt')\n",
    "\n",
    "# save model to Google Drive\n",
    "if isColabRunning:\n",
    "    saveToDrive('model_transfer.pt')\n",
    "\n",
    "# load the model that got the best validation accuracy (uncomment the line below)\n",
    "model_transfer.load_state_dict(torch.load('model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xl2BY5FQa0uz"
   },
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Use the code cell below to calculate and print the test loss and accuracy.  Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OKJp4enYa0uz"
   },
   "outputs": [],
   "source": [
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3jEkAVPa0uz"
   },
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan hound`, etc) that is predicted by your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhKeC8PUa0u1"
   },
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "  \n",
    "# list of class names by index, i.e. a name can be accessed like class_names[0]\n",
    "class_names = [item[4:].replace(\"_\", \" \") for item in loaders_transfer['train'].dataset.classes]\n",
    "\n",
    "def predict_breed_transfer(img_path):\n",
    "    # load the image and return the predicted breed\n",
    "    image = Image.open(img_path).convert(mode='RGB')\n",
    "    IMAGE_SIZE = 224\n",
    "    # preprocess the image using transform\n",
    "    prediction_transform = transforms.Compose([\n",
    "                                        transforms.Resize(256),\n",
    "                                        transforms.CenterCrop(IMAGE_SIZE),\n",
    "                                        transforms.ToTensor(),\n",
    "                                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225] )\n",
    "                                        ])\n",
    "    image_tensor = prediction_transform(image).unsqueeze(0)\n",
    "    # move to GPU\n",
    "    if use_cuda:\n",
    "        image_tensor = image_tensor.cuda()\n",
    "    \n",
    "    # set to evaluation mode for inferencing\n",
    "    model_transfer.eval()\n",
    "    idx = torch.argmax(model_transfer(image_tensor))\n",
    "    return class_names[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uoCv2xYSa0u2"
   },
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `dog_detector` functions developed above.  You are __required__ to use your CNN from Step 4 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](https://github.com/reedemus/dog_breed_classifier/blob/transfer-learning/images/sample_human_output.png?raw=1)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "353cW-uHa0u2"
   },
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "def run_app(img_path):\n",
    "    '''handle cases for a human face, dog, and neither'''\n",
    "    # open image\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    # predict its breed\n",
    "    breed = predict_breed_transfer(img_path)\n",
    "    \n",
    "    if face_detector(img_path) == True:\n",
    "        className = predict_breed_transfer(img_path)\n",
    "        msg = \"You are not a dog...but sure looks like a \" + str(className)\n",
    "    elif dog_detector(img_path) == True:\n",
    "        className = predict_breed_transfer(img_path)\n",
    "        msg = \"I'm guessing your dog is a \" + str(className) + \"!\"\n",
    "    else:\n",
    "        msg = \"Not a dog or human...what are you?\"\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(msg)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86J01l-Ma0u3"
   },
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that _you_ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m-f3vJPa0u3"
   },
   "source": [
    "__Answer:__ (Three possible points for improvement)\n",
    "<br> Yes, the outputs are more accurate than the model output from the CNN designed from scratch.\n",
    "However, the model is unable to classify the last dog image which contains a yellow ball. Some improvements that can be tried are:\n",
    "1. Add more variety of images to the dog train dataset, which includes a dog with a ball.\n",
    "> a quick glance on the train dataset shows there is no dog images with a ball.\n",
    "2. Increase the training sample size for this dog breed class by finding more photos.\n",
    "3. Resize and crop the test image before feeding into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZZ3J-u8na0u4"
   },
   "outputs": [],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed.\n",
    "\n",
    "## suggested code, below\n",
    "for file in np.hstack((human_files[:3], dog_files[:3])):\n",
    "    run_app(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "dog_app.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
